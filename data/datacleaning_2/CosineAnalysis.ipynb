{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956bc1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\baobr\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245d05f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2729b664f44c0da367750624205a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baobr\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\baobr\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965e1fc264204a739de740ad3c2bb81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effc68a313774729a49efbd3c56bed77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ed3b79cbfa4c48bf3dc96663c8f81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae972c438484328a05323c701868603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8395f8215c71417cbf871b22be9cfec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f051f20330a47b289dbb6232a843465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181154f6acbc4bbbaa64adfd0cb67c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9f33081b01420e990b2fabc829752c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6f80725fa64008b5dba40ee5499e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962bb6c4a6b3437aa3f5384e9dce5567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9adf0531fc4634b75d73f2cc4a6330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted speaker: soldiers\n",
      "soldiers         0.552\n",
      "eurylochus       0.535\n",
      "odysseus         0.466\n",
      "scylla           0.433\n",
      "poseidon         0.427\n"
     ]
    }
   ],
   "source": [
    "# Load your CSV of all lines\n",
    "df = pd.read_csv(\"epic_all_songs_lines.csv\")\n",
    "\n",
    "# Load a pretrained embedding model (use any from https://huggingface.co/sentence-transformers)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Compute embeddings for every line\n",
    "df['embedding'] = list(model.encode(df['line'], convert_to_numpy=True, show_progress_bar=True))\n",
    "\n",
    "# 1️⃣ Build one vector per speaker (mean of all their lines)\n",
    "speaker_vecs = (\n",
    "    df.groupby('speaker')['embedding']\n",
    "      .apply(lambda v: v.tolist())\n",
    "      .apply(lambda lst: sum(lst) / len(lst))\n",
    ")\n",
    "\n",
    "# 2️⃣ Given a new line, compute its vector\n",
    "test_line = \"We must keep rowing through the storm\"\n",
    "test_vec = model.encode(test_line, convert_to_numpy=True)\n",
    "\n",
    "# 3️⃣ Compare with each speaker using cosine similarity\n",
    "import numpy as np\n",
    "\n",
    "def cosine(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "scores = {spk: cosine(test_vec, vec) for spk, vec in speaker_vecs.items()}\n",
    "pred_speaker = max(scores, key=scores.get)\n",
    "\n",
    "print(\"Predicted speaker:\", pred_speaker)\n",
    "for spk, s in sorted(scores.items(), key=lambda x: -x[1])[:5]:\n",
    "    print(f\"{spk:15s}  {s:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dca56a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers kept: 34\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "df = pd.read_csv(\"epic_all_songs_lines.csv\")\n",
    "\n",
    "# Choose the text column you want to classify\n",
    "TEXT_COL = \"line\" if \"line\" in df.columns else \"stanza\"\n",
    "\n",
    "# (Optional) normalize speaker labels\n",
    "df[\"speaker\"] = df[\"speaker\"].str.strip()\n",
    "\n",
    "# (Optional) drop very rare speakers (e.g., < 5 lines) to avoid tiny classes\n",
    "min_lines = 5\n",
    "counts = df[\"speaker\"].value_counts()\n",
    "keep_speakers = counts[counts >= min_lines].index\n",
    "df = df[df[\"speaker\"].isin(keep_speakers)].reset_index(drop=True)\n",
    "print(\"Speakers kept:\", len(keep_speakers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12a7127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[TEXT_COL], df[\"speaker\"],\n",
    "    test_size=0.2, random_state=42, stratify=df[\"speaker\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21189497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8890b25022c4190a5c7d51a798b1bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5734485f94e4cf0ac2dc59b7a40e9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "X_train_emb = model.encode(X_train.tolist(), convert_to_numpy=True, show_progress_bar=True)\n",
    "X_test_emb  = model.encode(X_test.tolist(),  convert_to_numpy=True, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1db99098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each training vector to its speaker\n",
    "train_df = pd.DataFrame({\"speaker\": y_train.values})\n",
    "train_df[\"idx\"] = np.arange(len(train_df))\n",
    "train_df[\"vec\"] = list(X_train_emb)\n",
    "\n",
    "centroids = (\n",
    "    train_df.groupby(\"speaker\")[\"vec\"]\n",
    "    .apply(lambda vs: np.mean(np.stack(list(vs)), axis=0))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Also prepare an ordered list of speakers for vectorized scoring\n",
    "speakers = np.array(list(centroids.keys()))\n",
    "centroid_mat = np.stack([centroids[s] for s in speakers])  # shape: (S, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb07a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine(a,b) = a·b / (||a|| ||b||)\n",
    "def cosine_matrix(A, B):\n",
    "    A_norm = A / np.linalg.norm(A, axis=1, keepdims=True)\n",
    "    B_norm = B / np.linalg.norm(B, axis=1, keepdims=True)\n",
    "    return A_norm @ B_norm.T  # shape: (len(A), len(B))\n",
    "\n",
    "S = cosine_matrix(X_test_emb, centroid_mat)     # (N_test, S)\n",
    "top1_idx = S.argmax(axis=1)\n",
    "y_pred = speakers[top1_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dec51ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 0.186\n",
      "Top-3 accuracy: 0.510\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         aeolus      0.200     0.143     0.167         7\n",
      "            all      0.105     0.250     0.148         8\n",
      "      antinuous      0.000     0.000     0.000        17\n",
      "      aphrodite      0.000     0.000     0.000         1\n",
      "         apollo      0.000     0.000     0.000         1\n",
      "           ares      0.000     0.000     0.000         2\n",
      "         athena      0.077     0.048     0.059        21\n",
      "        calypso      0.345     0.556     0.426        18\n",
      "          circe      0.154     0.286     0.200        14\n",
      "           crew      0.111     0.091     0.100        11\n",
      "       cyclopes      0.333     1.000     0.500         1\n",
      "       ensemble      0.000     0.000     0.000        22\n",
      "     eurylochus      0.156     0.263     0.196        19\n",
      "fallen soldiers      0.000     0.000     0.000         1\n",
      "     hephaestus      0.000     0.000     0.000         1\n",
      "           hera      0.000     0.000     0.000         1\n",
      "         hermes      0.304     0.368     0.333        19\n",
      " laestrygonians      0.231     0.375     0.286         8\n",
      "   lotus eaters      0.333     1.000     0.500         2\n",
      "       odysseus      0.385     0.035     0.064       144\n",
      "       penelope      0.172     0.294     0.217        17\n",
      "      perimedes      0.100     1.000     0.182         1\n",
      "        polites      0.429     0.300     0.353        10\n",
      "     polyphemus      0.143     0.167     0.154         6\n",
      "       poseidon      0.176     0.136     0.154        22\n",
      "         scylla      0.000     0.000     0.000         2\n",
      "         sirens      0.091     1.000     0.167         1\n",
      "       soldiers      0.256     0.306     0.278        36\n",
      "        suitors      0.217     0.455     0.294        11\n",
      "     telemachus      0.273     0.429     0.333        14\n",
      "    the suitors      0.375     0.500     0.429         6\n",
      "       tiresias      0.167     0.333     0.222         3\n",
      "        winions      0.182     0.400     0.250         5\n",
      "           zeus      0.074     0.182     0.105        11\n",
      "\n",
      "       accuracy                          0.186       463\n",
      "      macro avg      0.159     0.292     0.180       463\n",
      "   weighted avg      0.243     0.186     0.159       463\n",
      "\n",
      "\n",
      "Confusion matrix (head):\n",
      "                pred:aeolus  pred:all  pred:antinuous  pred:aphrodite  \\\n",
      "true:aeolus               1         0               1               0   \n",
      "true:all                  0         2               0               0   \n",
      "true:antinuous            0         1               0               0   \n",
      "true:aphrodite            0         0               0               0   \n",
      "true:apollo               0         0               0               0   \n",
      "true:ares                 0         0               0               0   \n",
      "true:athena               0         0               1               0   \n",
      "true:calypso              0         0               0               0   \n",
      "true:circe                0         0               0               0   \n",
      "true:crew                 0         1               0               0   \n",
      "\n",
      "                pred:apollo  pred:ares  pred:athena  pred:calypso  pred:circe  \\\n",
      "true:aeolus               0          0            0             0           0   \n",
      "true:all                  0          0            0             0           0   \n",
      "true:antinuous            0          0            0             0           0   \n",
      "true:aphrodite            0          0            0             0           0   \n",
      "true:apollo               0          0            0             0           0   \n",
      "true:ares                 0          0            0             0           0   \n",
      "true:athena               0          0            1             0           1   \n",
      "true:calypso              0          0            0            10           1   \n",
      "true:circe                0          1            1             0           4   \n",
      "true:crew                 0          0            1             0           0   \n",
      "\n",
      "                pred:crew  \n",
      "true:aeolus             0  \n",
      "true:all                0  \n",
      "true:antinuous          0  \n",
      "true:aphrodite          0  \n",
      "true:apollo             0  \n",
      "true:ares               1  \n",
      "true:athena             2  \n",
      "true:calypso            0  \n",
      "true:circe              1  \n",
      "true:crew               1  \n"
     ]
    }
   ],
   "source": [
    "# Overall accuracy\n",
    "acc = (y_pred == y_test.values).mean()\n",
    "print(f\"Top-1 accuracy: {acc:.3f}\")\n",
    "\n",
    "# Top-k accuracy (e.g., k=3)\n",
    "k = 3\n",
    "topk_idx = np.argpartition(S, -k, axis=1)[:, -k:]\n",
    "topk_hits = np.array([y_test.values[i] in speakers[topk_idx[i]] for i in range(len(y_test))]).mean()\n",
    "print(f\"Top-{k} accuracy: {topk_hits:.3f}\")\n",
    "\n",
    "# Per-class precision/recall/F1\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=speakers)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"true:{s}\" for s in speakers], columns=[f\"pred:{s}\" for s in speakers])\n",
    "print(\"\\nConfusion matrix (head):\")\n",
    "print(cm_df.iloc[:10, :10])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
