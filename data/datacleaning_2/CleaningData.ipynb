{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f42a9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24534162",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.allmusicals.com/e/epicthemusical.htm\"\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# ðŸ”¹ Step 1: find the section containing all the song links\n",
    "lyric_section = soup.find(class_=\"lyrics-list\")\n",
    "\n",
    "ol = lyric_section.find(\"ol\") # where the actual links are\n",
    "\n",
    "# ðŸ”¹ Step 2: extract <a> tags within that section\n",
    "song_links = []\n",
    "current_act = None\n",
    "\n",
    "# Iterate over direct <li> children of <ol>\n",
    "for li in ol.find_all(\"li\", recursive = False):\n",
    "    classes = li.get(\"class\", [])\n",
    "\n",
    "    # Act header like <li class=\"act\"><strong><span>Act I</span></strong></li>\n",
    "    if \"act\" in classes:\n",
    "        current_act = li.get_text(\" \", strip=True) or None\n",
    "        print(current_act)\n",
    "        continue\n",
    "\n",
    "    for a in lyric_section.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"].strip()\n",
    "        abs_url = urljoin(url, href)\n",
    "        title = a.get_text(strip=True)\n",
    "        # Optional: only keep Epic: The Musical song pages\n",
    "        if re.search(r\"/epicthemusical/.+\\.htm$\", abs_url, re.I):\n",
    "            song_links.append((title, abs_url, current_act))\n",
    "\n",
    "# ðŸ”¹ Step 3: remove duplicates while preserving order\n",
    "seen = set()\n",
    "unique_links = []\n",
    "for title, link, act in song_links:\n",
    "    if link not in seen:\n",
    "        unique_links.append((title, link, act))\n",
    "        seen.add(link)\n",
    "\n",
    "# ðŸ”¹ Step 4: print or save the result\n",
    "# print(f\"Found {len(unique_links)} songs:\")\n",
    "#for t, u, a in unique_links:\n",
    "    #print(f\"- {a} {t} -> {u}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "90fb011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Step 1: find the section containing all the song links\n",
    "lyric_section = soup.find(\"section\", class_=\"lyrics-list\")\n",
    "ol = lyric_section.find(\"ol\")  # where the actual links are\n",
    "\n",
    "# ðŸ”¹ Step 2: extract links, tracking the current act label\n",
    "song_links = []\n",
    "current_act = None\n",
    "\n",
    "for li in ol.find_all(\"li\", recursive=False):\n",
    "    classes = li.get(\"class\", [])\n",
    "\n",
    "    # Act header like <li class=\"act\">Act I</li>\n",
    "    if \"act\" in classes:\n",
    "        current_act = li.get_text(\" \", strip=True) or None\n",
    "        # print(current_act)\n",
    "        continue\n",
    "\n",
    "    # âœ… FIXED: search anchors inside THIS li\n",
    "    for a in li.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"].strip()\n",
    "        abs_url = urljoin(url, href)\n",
    "        title = a.get_text(strip=True)\n",
    "        if re.search(r\"/epicthemusical/.+\\.htm$\", abs_url, re.I):\n",
    "            song_links.append((title, abs_url, current_act))\n",
    "\n",
    "# ðŸ”¹ De-dup\n",
    "seen = set()\n",
    "unique_links = []\n",
    "for title, link, act in song_links:\n",
    "    key = link.lower()\n",
    "    if key not in seen:\n",
    "        unique_links.append((title, link, act))\n",
    "        seen.add(key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b84734b",
   "metadata": {},
   "source": [
    "## Getting Song Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "add37be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEAKER_LINE = re.compile(r'^\\s*\\[(.+?)\\]\\s*$')   # e.g., [ODYSSEUS, CREW]\n",
    "\n",
    "def split_speakers(s: str):\n",
    "    \"\"\"\n",
    "    Turn 'ODYSSEUS, CREW & NARRATOR' into ['ODYSSEUS','CREW','NARRATOR'].\n",
    "    \"\"\"\n",
    "    # normalize separators\n",
    "    s = re.sub(r'\\s*(?:,|&|and|/|\\+)\\s*', ',', s, flags=re.I)\n",
    "    parts = [p.strip() for p in s.split(',') if p.strip()]\n",
    "    return parts or [\"UNKNOWN\"]\n",
    "\n",
    "def parse_song_page(title: str, url: str, act: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a DataFrame with columns: song, speaker, line\n",
    "    (one row per speaker per line).\n",
    "    \"\"\"\n",
    "    r = requests.get(url, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # ---- locate the content ----\n",
    "    page = soup.find(id=\"page\")\n",
    "    if not page:\n",
    "        raise ValueError(\"Could not find <div id='page'> on this page.\")\n",
    "    \n",
    "    # song title (prefer the printed h2; fall back to <title>)\n",
    "    h2 = page.find(\"h2\")\n",
    "    song_title = title;\n",
    "    #song_title = (h2.get_text(strip=True) if h2\n",
    "    #              else (soup.title.get_text(strip=True) if soup.title else \"Unknown Song\"))\n",
    "\n",
    "    # Get the page text with explicit line breaks at <br>\n",
    "    text = page.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    rows = []\n",
    "    current_speakers = [\"UNKNOWN\"]\n",
    "    prev_speaker_groups = []   # <- keep a list of past speaker lists\n",
    "    for raw in text.splitlines():\n",
    "        line = raw.strip()\n",
    "\n",
    "        # ignore boilerplate/metadata lines\n",
    "        if not line or line.lower().startswith(\"last update\"):\n",
    "            continue\n",
    "\n",
    "        # speaker header like [ODYSSEUS, CREW]\n",
    "        m = SPEAKER_LINE.match(line)\n",
    "        if m:\n",
    "            speaker_text = m.group(1).strip()\n",
    "            # Handle special [BOTH] keyword\n",
    "            if speaker_text.lower() == \"both\":\n",
    "                flat_prev = [s for grp in prev_speaker_groups[-2:] for s in grp]\n",
    "                current_speakers = list(dict.fromkeys(flat_prev)) or [\"UNKNOWN\"]\n",
    "            else:\n",
    "                current_speakers = split_speakers(speaker_text)\n",
    "            prev_speaker_groups.append(current_speakers)\n",
    "            continue\n",
    "\n",
    "        # otherwise it's a lyric line â†’ one row per speaker\n",
    "        for spk in current_speakers:\n",
    "            rows.append({\"act\": act, \"song\": song_title, \"speaker\": spk, \"line\": line})\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "06223470",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Old one\n",
    "dfs = [] # apparently its faster to create a list of dataframes with the lines from each song and concat at end\n",
    "for t, u, a in unique_links:\n",
    "    df = parse_song_page(t, u, a) #url for each song\n",
    "    dfs.append(df)\n",
    "    # print(df.head(11))\n",
    "df_overall = pd.concat(dfs, ignore_index = True)\n",
    "df_overall.to_csv(\"epic_all_songs_lines.csv\", index=False, encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5776b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>song</th>\n",
       "      <th>speaker</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Troy Saga</td>\n",
       "      <td>The Horse and the Infant</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>The Horse and the Infant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Troy Saga</td>\n",
       "      <td>The Horse and the Infant</td>\n",
       "      <td>ODYSSEUS</td>\n",
       "      <td>Alright, my brothers, listen closely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Troy Saga</td>\n",
       "      <td>The Horse and the Infant</td>\n",
       "      <td>SOLDIERS</td>\n",
       "      <td>Alright, my brothers, listen closely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Troy Saga</td>\n",
       "      <td>The Horse and the Infant</td>\n",
       "      <td>ODYSSEUS</td>\n",
       "      <td>Tonight, we make the Trojans pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Troy Saga</td>\n",
       "      <td>The Horse and the Infant</td>\n",
       "      <td>SOLDIERS</td>\n",
       "      <td>Tonight, we make the Trojans pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>The Ithaca Saga</td>\n",
       "      <td>Would You Fall In Love With Me Again</td>\n",
       "      <td>PENELOPE</td>\n",
       "      <td>How long has it been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>The Ithaca Saga</td>\n",
       "      <td>Would You Fall In Love With Me Again</td>\n",
       "      <td>ODYSSEUS</td>\n",
       "      <td>Twenty years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>The Ithaca Saga</td>\n",
       "      <td>Would You Fall In Love With Me Again</td>\n",
       "      <td>PENELOPE</td>\n",
       "      <td>I love you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>The Ithaca Saga</td>\n",
       "      <td>Would You Fall In Love With Me Again</td>\n",
       "      <td>PENELOPE</td>\n",
       "      <td>I love you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>The Ithaca Saga</td>\n",
       "      <td>Would You Fall In Love With Me Again</td>\n",
       "      <td>ODYSSEUS</td>\n",
       "      <td>I love you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2466 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  act                                  song   speaker  \\\n",
       "0       The Troy Saga              The Horse and the Infant   UNKNOWN   \n",
       "1       The Troy Saga              The Horse and the Infant  ODYSSEUS   \n",
       "2       The Troy Saga              The Horse and the Infant  SOLDIERS   \n",
       "3       The Troy Saga              The Horse and the Infant  ODYSSEUS   \n",
       "4       The Troy Saga              The Horse and the Infant  SOLDIERS   \n",
       "...               ...                                   ...       ...   \n",
       "2461  The Ithaca Saga  Would You Fall In Love With Me Again  PENELOPE   \n",
       "2462  The Ithaca Saga  Would You Fall In Love With Me Again  ODYSSEUS   \n",
       "2463  The Ithaca Saga  Would You Fall In Love With Me Again  PENELOPE   \n",
       "2464  The Ithaca Saga  Would You Fall In Love With Me Again  PENELOPE   \n",
       "2465  The Ithaca Saga  Would You Fall In Love With Me Again  ODYSSEUS   \n",
       "\n",
       "                                      line  \n",
       "0                 The Horse and the Infant  \n",
       "1     Alright, my brothers, listen closely  \n",
       "2     Alright, my brothers, listen closely  \n",
       "3         Tonight, we make the Trojans pay  \n",
       "4         Tonight, we make the Trojans pay  \n",
       "...                                    ...  \n",
       "2461                 How long has it been?  \n",
       "2462                          Twenty years  \n",
       "2463                            I love you  \n",
       "2464                            I love you  \n",
       "2465                            I love you  \n",
       "\n",
       "[2466 rows x 4 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d4f0c",
   "metadata": {},
   "source": [
    "## Each Stanza as a Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37b5de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEAKER_LINE = re.compile(r'^\\s*\\[(.+?)\\]\\s*$')   # e.g. [ODYSSEUS, CREW]\n",
    "\n",
    "def split_speakers(s: str):\n",
    "    # normalize common separators: \"A, B & C / D + E and F\" â†’ ['A','B','C','D','E','F']\n",
    "    s = re.sub(r'\\s*(?:,|&|and|/|\\+)\\s*', ',', s, flags=re.I)\n",
    "    return [p.strip() for p in s.split(',') if p.strip()] or [\"UNKNOWN\"]\n",
    "\n",
    "def parse_song_page_stanzas(url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with columns: song, stanza_idx, speaker, stanza\n",
    "    - stanza = all consecutive lines a speaker (or speaker group) says until the next [SPEAKER] header\n",
    "    - duplicates one row per speaker if multiple speakers are listed\n",
    "    \"\"\"\n",
    "    r = requests.get(url, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    page = soup.find(id=\"page\")\n",
    "    if not page:\n",
    "        raise ValueError(\"No <div id='page'> found\")\n",
    "\n",
    "    # Prefer the visible-print h2 as the song title; fall back to <title>\n",
    "    h2 = page.find(\"h2\")\n",
    "    song_title = (h2.get_text(strip=True) if h2\n",
    "                  else (soup.title.get_text(strip=True) if soup.title else \"Unknown Song\"))\n",
    "\n",
    "    # Turn <br> into line breaks\n",
    "    text = page.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    rows = []\n",
    "    stanza_lines = []\n",
    "    stanza_idx = 0\n",
    "    current_speakers = [\"UNKNOWN\"]\n",
    "\n",
    "    def flush_stanza():\n",
    "        nonlocal stanza_lines, stanza_idx\n",
    "        if not stanza_lines:\n",
    "            return\n",
    "        stanza = \"\\n\".join(stanza_lines).strip()\n",
    "        # compress 3+ blank lines to at most one blank line\n",
    "        stanza = re.sub(r'\\n{3,}', '\\n\\n', stanza)\n",
    "        if stanza:\n",
    "            stanza_idx += 1\n",
    "            for spk in current_speakers:\n",
    "                rows.append({\n",
    "                    \"song\": song_title,\n",
    "                    \"stanza_idx\": stanza_idx,\n",
    "                    \"speaker\": spk,\n",
    "                    \"stanza\": stanza\n",
    "                })\n",
    "        stanza_lines = []\n",
    "\n",
    "    for raw in text.splitlines():\n",
    "        line = raw.strip()\n",
    "\n",
    "        # skip site footer noise\n",
    "        if not line or line.lower().startswith(\"last update\"):\n",
    "            # Keep blank lines as stanza separators (optional):\n",
    "            # stanza_lines.append(\"\")  # uncomment to preserve blank lines inside stanza\n",
    "            continue\n",
    "\n",
    "        m = SPEAKER_LINE.match(line)\n",
    "        if m:\n",
    "            # new speaker header â†’ finish previous stanza, switch speakers\n",
    "            flush_stanza()\n",
    "            current_speakers = split_speakers(m.group(1))\n",
    "        else:\n",
    "            stanza_lines.append(line)\n",
    "\n",
    "    # flush the trailing stanza at EOF\n",
    "    flush_stanza()\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20fa8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dfs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# apparently its faster to create a list of dataframes with the lines from each song and concat at end\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, u \u001b[38;5;129;01min\u001b[39;00m unique_links:\n\u001b[0;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m parse_song_page_stanzas(u) \u001b[38;5;66;03m#url for each song\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "dfs = [] # apparently its faster to create a list of dataframes with the lines from each song and concat at end\n",
    "for t, u, a in unique_links:\n",
    "    df = parse_song_page_stanzas(u) #url for each song\n",
    "    dfs.append(df)\n",
    "    # print(df.head(11))\n",
    "df_stanza = pd.concat(dfs, ignore_index = True)\n",
    "df_stanza.to_csv(\"epic_all_songs_stanza.csv\", index=False, encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca2bd5",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2966bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall[\"speaker\"] = df_overall[\"speaker\"].str.lower()\n",
    "df_overall = df_overall[df_overall[\"speaker\"] != \"UNKNOWN\"]\n",
    "df_overall = df_overall[df_overall[\"speaker\"] != \"spoken\"] #sometimes the label is [Oddesues, spoken]\n",
    "# or easier way:\n",
    "#drop_speakers = [\"UNKNOWN\", \"spoken\"]\n",
    "# df_overall = df_overall[~df_overall[\"speaker\"].isin(drop_speakers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "02fe8e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unknown' 'odysseus' 'soldiers' 'zeus' 'ensemble' 'all' 'crew'\n",
      " 'eurylochus' 'polites' 'odyssseus' 'lotus eaters' 'athena' 'polyphemus'\n",
      " 'soldier' 'cyclopes' 'perimedes' 'elpenor' 'aeolus' 'winions' 'penelope'\n",
      " 'telemachus' 'poseidon' 'laestrygonians' 'circe' 'hermes'\n",
      " 'fallen soldiers' 'tiresias' 'sirens' 'siren' 'scylla' 'antinuous'\n",
      " 'the suitors' 'telemahcus' 'calypso' 'apollo' 'hephaestus' 'aphrodite'\n",
      " 'ares' 'hera' 'suitors' 'amphinomus']\n"
     ]
    }
   ],
   "source": [
    "print(df_overall[\"speaker\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7bf0dc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [act, song, speaker, line]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# print(df_overall[df_overall[\"speaker\"] == \"spoken\"])\n",
    "print(df_overall[df_overall[\"speaker\"] == \"both\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
