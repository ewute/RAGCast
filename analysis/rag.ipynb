{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f080bb",
   "metadata": {},
   "source": [
    "## Prereq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff0a5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da434e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY found in environment, proceeding...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Read OpenAI API key from environment for safety.\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "if not OPENAI_API_KEY:\n",
    "    raise EnvironmentError('Please set the OPENAI_API_KEY environment variable before running this notebook')\n",
    "print('OPENAI_API_KEY found in environment, proceeding...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a25fa04",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c621d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Use the CSV in the project data/clean directory (relative to analysis/)\n",
    "loader = TextLoader(\"../data/process/character_lines.csv\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3d644",
   "metadata": {},
   "source": [
    "## Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e6c02e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26328/2086565278.py:45: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()  # needs OPENAI_API_KEY env var (not printed)\n",
      "/tmp/ipykernel_26328/2086565278.py:47: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n",
      "/tmp/ipykernel_26328/2086565278.py:47: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odysseus {'source': 'train.csv', 'row': 24, 'character': 'Suitors'}\n",
      "Odysseus {'source': 'train.csv', 'row': 25, 'character': 'Odysseus'}\n",
      "Odysseus {'character': 'Suitors', 'row': 24, 'source': 'train.csv'}\n",
      "Odysseus {'character': 'Odysseus', 'row': 25, 'source': 'train.csv'}\n",
      "Just keep your eyes open\n",
      "\n",
      "Just keep your eyes open\n",
      "\n",
      "Just keep your eyes open\n",
      "\n",
      "Just keep your eyes open\n",
      "\n",
      "Wake up!\n",
      "\n",
      "Wake up, Odysseus, they're opening the bag\n",
      "\n",
      "Wake up! {'character': 'Penelope', 'row': 31, 'source': 'train.csv'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "csv_path = \"../data/clean/train.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Detect likely columns\n",
    "possible_char_cols = [\"character\"]\n",
    "possible_text_cols = [\"lines\"]\n",
    "\n",
    "char_col = next((c for c in possible_char_cols if c in df.columns), None)\n",
    "text_col = next((c for c in possible_text_cols if c in df.columns), None)\n",
    "\n",
    "# fallback: if only two columns, assume first is character, second is text\n",
    "if char_col is None or text_col is None:\n",
    "    cols = list(df.columns)\n",
    "    if len(cols) >= 2:\n",
    "        char_col = char_col or cols[0]\n",
    "        text_col = text_col or cols[1]\n",
    "    else:\n",
    "        # assume single-column CSV, each row may be \"CHARACTER: line\"\n",
    "        char_col = None\n",
    "        text_col = cols[0]\n",
    "\n",
    "docs = []\n",
    "for idx, row in df.iterrows():\n",
    "    raw_text = str(row[text_col]) if text_col in row else str(row[0])\n",
    "    if not raw_text or raw_text.strip() == \"\":\n",
    "        continue\n",
    "    metadata = {\"source\": os.path.basename(csv_path), \"row\": int(idx)}\n",
    "    if char_col and char_col in row:\n",
    "        metadata[\"character\"] = str(row[char_col])\n",
    "    else:\n",
    "        # try to parse \"CHARACTER: text\" pattern\n",
    "        if \":\" in raw_text:\n",
    "            maybe_char, maybe_line = raw_text.split(\":\", 1)\n",
    "            metadata[\"character\"] = maybe_char.strip()\n",
    "            raw_text = maybe_line.strip()\n",
    "    docs.append(Document(page_content=raw_text, metadata=metadata))\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings()  # needs OPENAI_API_KEY env var (not printed)\n",
    "vectordb = Chroma.from_documents(docs, embeddings, persist_directory=\"./chroma_lines\")\n",
    "vectordb.persist()\n",
    "\n",
    "# Example query\n",
    "results = vectordb.similarity_search(\"Find lines where Odysseus expresses longing\", k=5)\n",
    "for r in results:\n",
    "    print(r.page_content, r.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25bcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "630256d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The character in the epic most likely to say these words is **Odysseus**.\n",
      "\n",
      "**Reasoning:**  \n",
      "- The lines express frustration, exhaustion, and a plea to **Poseidon**, the god who relentlessly persecutes Odysseus after he blinds the Cyclops Polyphemus (Poseidon's son).\n",
      "- Odysseus is famously kept from returning home for many years (ten years after the Trojan War), largely due to Poseidon’s wrath.\n",
      "- The tone (\"It's been 8 years, how long will this go?\") fits Odysseus' situation, as he is desperate to return to Ithaca and wants Poseidon’s punishment to end.\n",
      "- The sense of mutual suffering and loss also fits Odysseus’ perspective, as he has lost crew and time, and Poseidon has lost his son’s eye.\n",
      "\n",
      "**Conclusion:**  \n",
      "**Odysseus** would be the character in the epic most likely to plead with Poseidon in this manner.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1\")\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "query = \"which character in epic would say: Wait  Stop this, please  NO  Aren't you tired, Poseidon?  It's been 8 years, how long will this go?  We're both hurting from losses  So why not leave this here and just go home?\"\n",
    "response = qa_chain.invoke({\"query\": query})\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma # Or FAISS or others\n",
    "from langchain.schema import Document\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Params\n",
    "FOLDER_PATH = \"../data_new/speakertext_train\"  # replace with your folder path\n",
    "QUERY = \"Your query goes here\"\n",
    "CROSS_ENCODER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "CHROMA_DB_PATH = \"langchain_db\"\n",
    "\n",
    "# Step 1: Load text files\n",
    "documents = []\n",
    "for fname in os.listdir(FOLDER_PATH):\n",
    "    if fname.endswith(\".txt\"):\n",
    "        with open(os.path.join(FOLDER_PATH, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            doc_text = f.read()\n",
    "        documents.append((fname, doc_text))\n",
    "\n",
    "# Step 2: Score relevance with cross encoder\n",
    "cross_encoder = CrossEncoder(CROSS_ENCODER_MODEL)\n",
    "scores = cross_encoder.predict([(QUERY, doc[1]) for doc in documents])\n",
    "\n",
    "# Optional: Filter based on a score threshold if desired\n",
    "RELEVANCE_THRESHOLD = 0.0  # update as needed\n",
    "selected_documents = [\n",
    "    Document(page_content=doc[1], metadata={\"filename\": doc[0], \"score\": float(score)})\n",
    "    for doc, score in zip(documents, scores)\n",
    "    if score >= RELEVANCE_THRESHOLD\n",
    "]\n",
    "\n",
    "# Step 3: Add to vector database using LangChain\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vectordb = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=embeddings)\n",
    "vectordb.add_documents(selected_documents)\n",
    "vectordb.persist()\n",
    "\n",
    "print(f\"Added {len(selected_documents)} relevant documents to the database.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
