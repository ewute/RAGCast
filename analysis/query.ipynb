{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1123a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "807a6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY set in os.environ\n"
     ]
    }
   ],
   "source": [
    "# Set the OpenAI API key in the Python environment.\n",
    "# `os` is already imported in a later cell, so we can use it here without re-importing.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key_here\"\n",
    "\n",
    "# Optional confirmation (does not print the secret)\n",
    "print(\"OPENAI_API_KEY set in os.environ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72c4daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"../data_new/speaker_texts/train\", glob=\"**/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bebe20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.directory.DirectoryLoader at 0x70fc91245700>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bace9cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.18-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: charset-normalizer in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (3.3.2)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (5.3.0)\n",
      "Requirement already satisfied: nltk in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: requests in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (4.12.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.11.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (2.2.6)\n",
      "Requirement already satisfied: rapidfuzz in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (3.13.0)\n",
      "Requirement already satisfied: backoff in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (4.12.2)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.42.4-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: wrapt in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ewu/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ewu/anaconda3/lib/python3.12/site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ewu/anaconda3/lib/python3.12/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ewu/anaconda3/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
      "Requirement already satisfied: mypy_extensions>=0.3.0 in /home/ewu/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/ewu/anaconda3/lib/python3.12/site-packages (from html5lib->unstructured) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/ewu/anaconda3/lib/python3.12/site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in /home/ewu/anaconda3/lib/python3.12/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ewu/anaconda3/lib/python3.12/site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ewu/anaconda3/lib/python3.12/site-packages (from nltk->unstructured) (2024.11.6)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ewu/anaconda3/lib/python3.12/site-packages (from requests->unstructured) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ewu/anaconda3/lib/python3.12/site-packages (from requests->unstructured) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ewu/anaconda3/lib/python3.12/site-packages (from requests->unstructured) (2025.10.5)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-25.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: cryptography>=3.1 in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured) (43.0.3)\n",
      "Collecting httpcore>=1.0.9 (from unstructured-client->unstructured)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured) (0.27.0)\n",
      "Collecting pydantic>=2.11.2 (from unstructured-client->unstructured)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting pypdf>=6.2.0 (from unstructured-client->unstructured)\n",
      "  Downloading pypdf-6.2.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/ewu/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ewu/anaconda3/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/ewu/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.21)\n",
      "Collecting h11>=0.16 (from httpcore>=1.0.9->unstructured-client->unstructured)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: anyio in /home/ewu/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.6.2)\n",
      "Requirement already satisfied: sniffio in /home/ewu/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ewu/anaconda3/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.6.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.11.2->unstructured-client->unstructured)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-extensions (from unstructured)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ewu/anaconda3/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.2)\n",
      "Downloading unstructured-0.18.18-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading python_iso639-2025.11.11-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading unstructured_client-0.42.4-py3-none-any.whl (207 kB)\n",
      "Downloading aiofiles-25.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-6.2.0-py3-none-any.whl (326 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "\u001b[33m  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993284 sha256=7a025375cf3433c30256008b7ab9ce55c83c7a2cd33c1c2edcdc489006624475\n",
      "  Stored in directory: /home/ewu/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, typing-extensions, python-magic, python-iso639, pypdf, olefile, langdetect, html5lib, h11, emoji, aiofiles, python-oxmsg, pydantic-core, httpcore, pydantic, unstructured-client, unstructured\n",
      "\u001b[2K  Attempting uninstall: typing-extensions\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.12.2\n",
      "\u001b[2K    Uninstalling typing_extensions-4.12.2:\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.12.2━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: pypdf━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: pypdf 6.1.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling pypdf-6.1.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled pypdf-6.1.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: h11m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [html5lib]ions]\n",
      "\u001b[2K    Found existing installation: h11 0.14.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [html5lib]\n",
      "\u001b[2K    Uninstalling h11-0.14.0:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [html5lib]\n",
      "\u001b[2K      Successfully uninstalled h11-0.14.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [html5lib]\n",
      "\u001b[2K  Attempting uninstall: pydantic-core0m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [html5lib]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.27.1━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [html5lib]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.27.1:m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [html5lib]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.27.1━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [html5lib]\n",
      "\u001b[2K  Attempting uninstall: httpcore━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Found existing installation: httpcore 1.0.2[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Uninstalling httpcore-1.0.2:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [pydantic-core]\n",
      "\u001b[2K      Successfully uninstalled httpcore-1.0.2m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [pydantic-core]\n",
      "\u001b[2K  Attempting uninstall: pydantic\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Found existing installation: pydantic 2.10.390m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Uninstalling pydantic-2.10.3:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [pydantic-core]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.10.3\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [pydantic-core]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [unstructured][0m [unstructured]client]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.41.1 requires protobuf<6,>=3.20, but you have protobuf 6.32.1 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.3.11 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-25.1.0 emoji-2.15.0 filetype-1.2.0 h11-0.16.0 html5lib-1.1 httpcore-1.0.9 langdetect-1.0.9 olefile-0.47 pydantic-2.12.4 pydantic-core-2.41.5 pypdf-6.2.0 python-iso639-2025.11.11 python-magic-0.4.27 python-oxmsg-0.0.2 typing-extensions-4.15.0 unstructured-0.18.18 unstructured-client-0.42.4\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee6c170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a30ed26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7e921c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for d in docs:\n",
    "    # e.g. source = \".../Odysseus.txt\" → \"Odysseus\"\n",
    "    fname = Path(d.metadata[\"source\"]).stem\n",
    "    d.metadata[\"character\"] = fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5598c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings()  # uses OPENAI_API_KEY\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4044ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def predict_speaker(\n",
    "    line: str,\n",
    "    k: int = 33\n",
    ") -> Tuple[str, List[Document]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - predicted_character: character name from best-matching document\n",
    "      - results: top-k matching documents for inspection\n",
    "    \"\"\"\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "    results: List[Document] = retriever.get_relevant_documents(line)\n",
    "\n",
    "    if not results:\n",
    "        return \"UNKNOWN\", []\n",
    "\n",
    "    top = results[0]\n",
    "    predicted_character = top.metadata.get(\"character\", \"UNKNOWN\")\n",
    "    return predicted_character, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c81f8870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted speaker: Laestrygonians\n",
      "--- top hit meta ---\n",
      "{'source': '../data_new/speaker_texts/train/Laestrygonians.txt', 'character': 'Laestrygonians'}\n",
      "--- snippet of that doc ---\n",
      "You are far too nice\n",
      "\n",
      "Unless, of course, you apologize\n",
      "\n",
      "Ruthlessness is (Captain) mercy upon our- Captain\n",
      "\n",
      "Poseidon, Poseidon, Poseidon, Poseidon, Poseidon, Poseidon, Poseidon\n",
      "\n",
      "Ruthlessness is (Captain) mercy upon our- Captain\n",
      "\n",
      "Had you just killed my son\n",
      "\n",
      "Ruthl?ssness is mercy upon ourselv?s\n",
      "\n",
      "I've gotta make you bleed\n",
      "\n",
      "You reveal your name\n",
      "\n",
      "Unlike you I've got no mercy left to give 'cause\n",
      "\n",
      "You are the worst kind of good\n",
      "\n",
      "That's what I hate\n",
      "\n",
      "Ruthlessness is mercy-\n",
      "\n",
      "But before you go, I need to ma\n"
     ]
    }
   ],
   "source": [
    "query_line = \"Ruthlessness is mercy upon ourselves 'Cause you fight to save lives\"\n",
    "\n",
    "predicted_character, matches = predict_speaker(query_line)\n",
    "\n",
    "print(\"Predicted speaker:\", predicted_character)\n",
    "print(\"--- top hit meta ---\")\n",
    "print(matches[0].metadata)\n",
    "print(\"--- snippet of that doc ---\")\n",
    "print(matches[0].page_content[:500])  # just to sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e60ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-predicted speaker: Poseidon\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are given some example lines spoken by different characters from a script.\n",
    "Each block is labeled with the character name.\n",
    "\n",
    "Use the writing STYLE and content to decide who most likely says the QUERY line.\n",
    "Respond with ONLY the character name.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUERY LINE:\n",
    "\"{query}\"\n",
    "\"\"\")\n",
    "\n",
    "def predict_speaker_llm(line: str, k: int = 3) -> str:\n",
    "    results = vectorstore.similarity_search(line, k=k)\n",
    "\n",
    "    context_blocks = []\n",
    "    for doc in results:\n",
    "        char = doc.metadata.get(\"character\", \"UNKNOWN\")\n",
    "        # We can just show the first few hundred chars of each file as style examples\n",
    "        context_blocks.append(f\"[{char}]\\n{doc.page_content[:800]}\\n\")\n",
    "    context = \"\\n\".join(context_blocks)\n",
    "\n",
    "    chain = prompt | llm\n",
    "    resp = chain.invoke({\"context\": context, \"query\": line})\n",
    "    return resp.content.strip()\n",
    "\n",
    "speaker = predict_speaker_llm(query_line)\n",
    "print(\"LLM-predicted speaker:\", speaker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d0e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
